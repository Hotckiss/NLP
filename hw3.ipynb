{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GdLTPv3xdKi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"data/dataset_40163_1.txt\"\n",
    "TRAIN_DATA_NAME = \"data/train_sentences_extended.txt\"\n",
    "NES_NAME = \"data/train_nes_extended.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuWXjbpn7BxL"
   },
   "outputs": [],
   "source": [
    "stem = Mystem()\n",
    "i2t = {1:\"PERSON\" , 2:\"ORG\"}\n",
    "t2i = {'PERSON': 1, 'ORG': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(name):\n",
    "    with open(name, encoding='utf-8') as input_file:\n",
    "        return list(map(lambda l: re.split('(\\W)', l), input_file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7PQv3NkxdLf"
   },
   "outputs": [],
   "source": [
    "def read_labels():\n",
    "    res = []\n",
    "\n",
    "    with open(NES_NAME, encoding='utf-8') as input_file:\n",
    "        for line in input_file:\n",
    "            s, l, t = None, None, None\n",
    "\n",
    "            for w in line.split():\n",
    "                if w == \"EOL\":\n",
    "                    break\n",
    "                \n",
    "                if s is None:\n",
    "                    s = int(w)\n",
    "                elif l is None:\n",
    "                    l = int(w)\n",
    "                else:\n",
    "                    res.append((s, l, w))\n",
    "                    s, l, t = None, None, None\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpm8j82GIkwm"
   },
   "outputs": [],
   "source": [
    "def build_voc(data):\n",
    "    voc = defaultdict(int)\n",
    "\n",
    "    for s in data:\n",
    "        for w in s:\n",
    "            l = stem.lemmatize(w.lower())\n",
    "\n",
    "            if l not in voc:\n",
    "                voc[l] = len(voc) + 1\n",
    "\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1Ni4f8NxdLt"
   },
   "outputs": [],
   "source": [
    "X = read(TRAIN_DATA_NAME)\n",
    "Y = read_labels()\n",
    "voc = build_voc(X)\n",
    "pad_value = len(voc) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKKVAQeOxdMl"
   },
   "outputs": [],
   "source": [
    "def pad(data):\n",
    "    num_data = [torch.tensor([voc[stemmer.stem(word.lower())] for word in s]) for s in data]\n",
    "    return pad_sequence(num_data, batch_first=True, padding_value=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5VmPiTnKvYM"
   },
   "outputs": [],
   "source": [
    "def pos(data):\n",
    "    def collate(sent):\n",
    "        pos = []\n",
    "        idx = 0\n",
    "\n",
    "        for word in sent:\n",
    "            cur_l = len(word)\n",
    "            pos.append((idx, cur_l))\n",
    "            idx += cur_l\n",
    "        return pos\n",
    "    \n",
    "    return [collate(s) for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yT-kS5NxdMq"
   },
   "outputs": [],
   "source": [
    "X_padded, X_pos = pad(X), pos(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJdrIaH3xdM2"
   },
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    res = []\n",
    "    \n",
    "    for s, pos, tags in zip(X_padded, X_pos, Y):\n",
    "        y = []\n",
    "        pi, ti = 0, 0\n",
    "\n",
    "        for word in s:\n",
    "            if pi < len(pos) and ti < len(tags) and pos[pi][0] == tags[ti][0]:\n",
    "                y.append(t2i[tags[ti][2]])\n",
    "                ti += 1\n",
    "            else:\n",
    "                y.append(0)\n",
    "            \n",
    "            pi += 1\n",
    "        \n",
    "        res.append([sent.numpy(), y])\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34259,
     "status": "ok",
     "timestamp": 1574706886395,
     "user": {
      "displayName": "Андрей Кириленко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDdErtNOlpWVIvdIX3ya3wXG_6-v_dD4v77lEKrJg=s64",
      "userId": "17757563948952891213"
     },
     "user_tz": -180
    },
    "id": "8HOBgF9yxdM8",
    "outputId": "a1cdd9cd-110e-4a12-ae5a-e4856178e0c4"
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBV-OUxTxdNI"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(dataset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAssvCKbxdNM"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vs):\n",
    "        super(Model, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vs, 64)\n",
    "        self.lstm = nn.LSTM(64, 128, batch_first=True)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        lstm_, _ = self.lstm(self.word_embeddings(batch))\n",
    "        return F.log_softmax(self.fc2(self.dropout(lstm_)), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TidGCKaxdNd"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(voc) + 3\n",
    "epoch_cnt = 300\n",
    "batch_size = 256\n",
    "\n",
    "model = Model(vocab_size)\n",
    "model = model.float()\n",
    "model = model.to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xw73WgmxdNT"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size)\n",
    "    loss_train, loss_val = [], []\n",
    "            \n",
    "    for _ in epoch_cnt:\n",
    "        for batch_data in train_loader:\n",
    "            x, y = batch_data[:, 0].to(device), batch_data[:, 1].to(device).reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.long()).view(-1, 3)\n",
    "            loss = loss_function(output, y.long())\n",
    "            loss_train.append(loss)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_values = []\n",
    "            for batch_data in val_loader:\n",
    "                x, y = batch_data[:, 0].to(device), batch_data[:, 1].to(device).reshape(-1) \n",
    "                output = model(x.long()).view(-1, 3)\n",
    "                loss = loss_function(output, y.long())\n",
    "                loss_values.append(loss.item())\n",
    "            \n",
    "            loss_val.append(np.mean(np.array(loss_values)))\n",
    "\n",
    "    return loss_train, loss_val \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766869,
     "status": "ok",
     "timestamp": 1574707630007,
     "user": {
      "displayName": "Андрей Кириленко",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDdErtNOlpWVIvdIX3ya3wXG_6-v_dD4v77lEKrJg=s64",
      "userId": "17757563948952891213"
     },
     "user_tz": -180
    },
    "id": "ke_exZJWxdNs",
    "outputId": "3a8b03ee-c58b-4ae2-dc0c-c1dbdd31f051"
   },
   "outputs": [],
   "source": [
    "loss_train, loss_val = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chMdvjzjxdN9"
   },
   "outputs": [],
   "source": [
    "test = read_input()\n",
    "test_padded = pad(test)\n",
    "test_pos = pos(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJ3_rkDCxdOF"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_loader = DataLoader(test_padded, batch_size=batch_size)\n",
    "    ans = None\n",
    "    \n",
    "    for batch_data in test_loader:\n",
    "        x = batch_data.to(device)\n",
    "        output = model(x.long())\n",
    "        _, ansx = output.max(dim=2)\n",
    "        ansx = ansx.cpu().numpy()\n",
    "        if ans is None:\n",
    "            ans = ansx\n",
    "        else:\n",
    "            ans = np.append(ans, ansx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B29hzFLOxdOJ"
   },
   "outputs": [],
   "source": [
    "with open(\"data/output.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for sent, pos, tags in zip(test_padded, test_pos, ans):\n",
    "        for i in range(len(pos)):\n",
    "            if tags[i] == 1 or tags[i] == 2:\n",
    "                output_file.write(str(pos[i][0]) + \" \" + str(pos[i][1]) + \" \" + str(i2t[tags[i]]))\n",
    "        output_file.write(\"EOL\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of HSE_NLP_task3.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/VadimFarutin/natural-language-processing/blob/master/task3.ipynb",
     "timestamp": 1574704360919
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
